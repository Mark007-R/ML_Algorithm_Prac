
---

## ğŸ“Œ Algorithms Covered

### ğŸ”¹ 1. Linear Regression
A supervised learning algorithm used to predict a continuous output based on one or more input features.

- **Concepts Covered:**
  - Line of best fit
  - Cost function (MSE)
  - Gradient descent
- **Implementation:** Using `scikit-learn` and from scratch

### ğŸ”¹ 2. Logistic Regression (Classification)
A classification algorithm used to predict the probability of a binary outcome.

- **Concepts Covered:**
  - Sigmoid function
  - Cost function (Log loss)
  - Decision boundary
- **Implementation:** Binary classification using `scikit-learn`

### ğŸ”¹ 3. Decision Trees
A supervised algorithm used for both classification and regression by creating a model that predicts the value of a target variable by learning decision rules from features.

- **Concepts Covered:**
  - Gini Index / Entropy
  - Information Gain
  - Tree pruning
- **Implementation:** Using `sklearn.tree.DecisionTreeClassifier`

### ğŸ”¹ 4. K-Means Clustering
An unsupervised learning algorithm that groups data into `k` clusters based on similarity.

- **Concepts Covered:**
  - Centroid initialization
  - Inertia and convergence
  - Elbow method
- **Implementation:** Using `sklearn.cluster.KMeans`

---

## ğŸ› ï¸ Technologies Used

- Python 3.x
- Jupyter Notebooks / Python scripts
- Libraries: `numpy`, `pandas`, `matplotlib`, `seaborn`, `scikit-learn`

---

## ğŸ’¡ Getting Started

1. **Clone the repo**
   ```bash
   git clone https://github.com/your-username/ML-Algorithms.git
   cd ML-Algorithms
